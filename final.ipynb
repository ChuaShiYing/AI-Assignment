{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43423403",
   "metadata": {},
   "source": [
    "### Install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f232cd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 1 — Install dependencies for cleaning + Marian training (from scratch) ===\n",
    "# - transformers/sentencepiece/accelerate: model + tokenizer + mixed precision\n",
    "# - datasets: dataset wrappers + Trainer input\n",
    "# - sacrebleu: BLEU/chrF evaluation\n",
    "# - nltk/jieba: tokenization, stemming/lemmatization (assignment requirement)\n",
    "# - scikit-learn: TF-IDF (assignment feature extraction requirement)\n",
    "# - matplotlib: simple plots for training curves\n",
    "!pip install -q transformers sentencepiece accelerate datasets sacrebleu nltk jieba scikit-learn matplotlib\n",
    "\n",
    "# minimal NLTK resources for tokenization/lemmatization demos\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8642a",
   "metadata": {},
   "source": [
    "### Imports & global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2b5065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Config saved to: marian_zh_en_scratch_run\\config.json\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2 — Imports & global configuration (from-scratch Marian training) ===\n",
    "from pathlib import Path\n",
    "import os, re, json, unicodedata, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "import sacrebleu  # for BLEU/chrF later\n",
    "\n",
    "# ---- Paths ----\n",
    "DATA_PATH = Path(\"/AI2/dataset_CN_EN.txt\")   # your CN<TAB>EN file\n",
    "RUN_DIR   = Path(\"marian_zh_en_scratch_run\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Reproducibility ----\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ---- Device ----\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ---- Training hyperparameters (scratch needs more steps; adjust if needed) ----\n",
    "EPOCHS         = 1          # increase if dataset is small\n",
    "LR             = 3e-4        # higher than fine-tune learning rate\n",
    "BSZ            = 16          # lower if OOM; you can use 8/4\n",
    "GRAD_ACCUM     = 1           # raise if you reduce BSZ\n",
    "WARMUP_RATIO   = 0.08\n",
    "WEIGHT_DECAY   = 1e-2\n",
    "LABEL_SMOOTH   = 0.1\n",
    "MAX_SRC        = 128         # truncation lengths (raise if VRAM allows)\n",
    "MAX_TGT        = 128\n",
    "LOG_STEPS      = 50\n",
    "\n",
    "# Persist a small run-config for reference\n",
    "cfg = {\n",
    "    \"seed\": SEED, \"device\": DEVICE, \"epochs\": EPOCHS, \"lr\": LR, \"batch_size\": BSZ,\n",
    "    \"grad_accum\": GRAD_ACCUM, \"warmup_ratio\": WARMUP_RATIO, \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"label_smooth\": LABEL_SMOOTH, \"max_src\": MAX_SRC, \"max_tgt\": MAX_TGT,\n",
    "    \"data_path\": str(DATA_PATH), \"run_dir\": str(RUN_DIR),\n",
    "}\n",
    "(RUN_DIR / \"config.json\").write_text(json.dumps(cfg, indent=2), encoding=\"utf-8\")\n",
    "print(\"Config saved to:\", RUN_DIR / \"config.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19969c6b",
   "metadata": {},
   "source": [
    "### Load raw dataset & BEFORE preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d52876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW shape: (20289, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>嗨。</td>\n",
       "      <td>Hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你好。</td>\n",
       "      <td>Hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>跑。</td>\n",
       "      <td>Run.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>等等！</td>\n",
       "      <td>Wait!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你好。</td>\n",
       "      <td>Hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>让我来。</td>\n",
       "      <td>I try.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>我赢了。</td>\n",
       "      <td>I won!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>不会吧。</td>\n",
       "      <td>Oh no!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>乾杯!</td>\n",
       "      <td>Cheers!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>他跑了。</td>\n",
       "      <td>He ran.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cn       en\n",
       "0    嗨。      Hi.\n",
       "1   你好。      Hi.\n",
       "2    跑。     Run.\n",
       "3   等等！    Wait!\n",
       "4   你好。   Hello!\n",
       "5  让我来。   I try.\n",
       "6  我赢了。   I won!\n",
       "7  不会吧。   Oh no!\n",
       "8   乾杯!  Cheers!\n",
       "9  他跑了。  He ran."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 3 — Load raw dataset & BEFORE preview ===\n",
    "from IPython.display import display\n",
    "\n",
    "assert DATA_PATH.exists(), f\"Missing dataset: {DATA_PATH}\"\n",
    "df_raw = pd.read_csv(DATA_PATH, sep=\"\\t\", header=None, names=[\"cn\",\"en\"], dtype=str)\n",
    "\n",
    "print(\"RAW shape:\", df_raw.shape)\n",
    "display(df_raw.head(10))  # BEFORE cleaning preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77810f",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082096a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows changed by cleaning: 3694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn_before</th>\n",
       "      <th>cn_after</th>\n",
       "      <th>en_before</th>\n",
       "      <th>en_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>嗨。</td>\n",
       "      <td>嗨。</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你好。</td>\n",
       "      <td>你好。</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>跑。</td>\n",
       "      <td>跑。</td>\n",
       "      <td>Run.</td>\n",
       "      <td>Run.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>等等！</td>\n",
       "      <td>等等!</td>\n",
       "      <td>Wait!</td>\n",
       "      <td>Wait!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你好。</td>\n",
       "      <td>你好。</td>\n",
       "      <td>Hello!</td>\n",
       "      <td>Hello!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>让我来。</td>\n",
       "      <td>让我来。</td>\n",
       "      <td>I try.</td>\n",
       "      <td>I try.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>我赢了。</td>\n",
       "      <td>我赢了。</td>\n",
       "      <td>I won!</td>\n",
       "      <td>I won!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>不会吧。</td>\n",
       "      <td>不会吧。</td>\n",
       "      <td>Oh no!</td>\n",
       "      <td>Oh no!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>乾杯!</td>\n",
       "      <td>乾杯!</td>\n",
       "      <td>Cheers!</td>\n",
       "      <td>Cheers!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>他跑了。</td>\n",
       "      <td>他跑了。</td>\n",
       "      <td>He ran.</td>\n",
       "      <td>He ran.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cn_before cn_after en_before en_after\n",
       "0        嗨。       嗨。       Hi.      Hi.\n",
       "1       你好。      你好。       Hi.      Hi.\n",
       "2        跑。       跑。      Run.     Run.\n",
       "3       等等！      等等!     Wait!    Wait!\n",
       "4       你好。      你好。    Hello!   Hello!\n",
       "5      让我来。     让我来。    I try.   I try.\n",
       "6      我赢了。     我赢了。    I won!   I won!\n",
       "7      不会吧。     不会吧。    Oh no!   Oh no!\n",
       "8       乾杯!      乾杯!   Cheers!  Cheers!\n",
       "9      他跑了。     他跑了。   He ran.  He ran."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 4 — Clean text + BEFORE/AFTER view (assignment: text cleaning) ===\n",
    "import re, unicodedata\n",
    "from IPython.display import display\n",
    "\n",
    "# zero-width chars set\n",
    "ZWSP = \"\".join([\"\\u200b\",\"\\u200c\",\"\\u200d\",\"\\ufeff\"])\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        s = \"\" if s is None else str(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)     # Unicode normalize\n",
    "    s = re.sub(f\"[{ZWSP}]\", \"\", s)           # remove zero-width chars\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()       # collapse whitespace\n",
    "    return s\n",
    "\n",
    "df = df_raw.copy()\n",
    "df[\"cn_clean\"] = df[\"cn\"].map(normalize)\n",
    "df[\"en_clean\"] = df[\"en\"].map(normalize)\n",
    "\n",
    "before_after = pd.DataFrame({\n",
    "    \"cn_before\": df_raw[\"cn\"], \"cn_after\": df[\"cn_clean\"],\n",
    "    \"en_before\": df_raw[\"en\"], \"en_after\": df[\"en_clean\"]\n",
    "})\n",
    "changed = int(((before_after.cn_before != before_after.cn_after) |\n",
    "               (before_after.en_before != before_after.en_after)).sum())\n",
    "print(\"Rows changed by cleaning:\", changed)\n",
    "\n",
    "display(before_after.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c54129",
   "metadata": {},
   "source": [
    "### Drop empties/duplicates & split (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8f5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After clean: 20285 rows (removed 4 empties + 4 duplicates)\n",
      "train=16228  valid=2028  test=2029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>麻煩您稍待一下。</td>\n",
       "      <td>Will you wait a moment?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你怎麼什麼話也沒說?</td>\n",
       "      <td>How come you didn't say anything?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我會告訴我的妻子。</td>\n",
       "      <td>I'll tell my wife.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你認為它是陷阱嗎?</td>\n",
       "      <td>Do you think it's a trap?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我们那时在谈论事情,但我不记得是什么了。</td>\n",
       "      <td>We were talking about something at that time, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     cn                                                 en\n",
       "0              麻煩您稍待一下。                            Will you wait a moment?\n",
       "1            你怎麼什麼話也沒說?                  How come you didn't say anything?\n",
       "2             我會告訴我的妻子。                                 I'll tell my wife.\n",
       "3             你認為它是陷阱嗎?                          Do you think it's a trap?\n",
       "4  我们那时在谈论事情,但我不记得是什么了。  We were talking about something at that time, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>她總是穿著黑色的衣服。</td>\n",
       "      <td>She always wears black.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>湯姆很可能遲到。</td>\n",
       "      <td>Tom is quite likely to be late.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>汤姆找不到玛丽。</td>\n",
       "      <td>Tom can't find Mary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>我的手抖得太厉害,没法穿针了。</td>\n",
       "      <td>My hands were shaking too much to thread the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我担心他的健康。</td>\n",
       "      <td>I was worried about his health.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cn                                                 en\n",
       "0      她總是穿著黑色的衣服。                            She always wears black.\n",
       "1         湯姆很可能遲到。                    Tom is quite likely to be late.\n",
       "2         汤姆找不到玛丽。                               Tom can't find Mary.\n",
       "3  我的手抖得太厉害,没法穿针了。  My hands were shaking too much to thread the n...\n",
       "4         我担心他的健康。                    I was worried about his health."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 5 — Drop empties/duplicates + deterministic 80/10/10 split ===\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "n0 = len(df)\n",
    "df2 = df.replace({\"\": np.nan}).dropna(subset=[\"cn_clean\",\"en_clean\"])\n",
    "dup_count = int(df2.duplicated(subset=[\"cn_clean\",\"en_clean\"]).sum())\n",
    "df2 = df2.drop_duplicates(subset=[\"cn_clean\",\"en_clean\"]).reset_index(drop=True)\n",
    "print(f\"After clean: {len(df2)} rows (removed {n0-len(df2)} empties + {dup_count} duplicates)\")\n",
    "\n",
    "# Deterministic shuffle & split\n",
    "rng = np.random.default_rng(SEED)\n",
    "idx = np.arange(len(df2)); rng.shuffle(idx)\n",
    "n = len(idx)\n",
    "i_train = idx[: int(0.8*n)]\n",
    "i_valid = idx[int(0.8*n): int(0.9*n)]\n",
    "i_test  = idx[int(0.9*n):]\n",
    "\n",
    "train_df = df2.iloc[i_train][[\"cn_clean\",\"en_clean\"]].rename(columns={\"cn_clean\":\"cn\",\"en_clean\":\"en\"}).reset_index(drop=True)\n",
    "valid_df = df2.iloc[i_valid][[\"cn_clean\",\"en_clean\"]].rename(columns={\"cn_clean\":\"cn\",\"en_clean\":\"en\"}).reset_index(drop=True)\n",
    "test_df  = df2.iloc[i_test ][[\"cn_clean\",\"en_clean\"]].rename(columns={\"cn_clean\":\"cn\",\"en_clean\":\"en\"}).reset_index(drop=True)\n",
    "\n",
    "print(f\"train={len(train_df)}  valid={len(valid_df)}  test={len(test_df)}\")\n",
    "display(train_df.head(5)); display(valid_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cfbb4",
   "metadata": {},
   "source": [
    "### Build Hugging Face Datasets & tokenize to token IDs (for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0475ac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch datasets: 16228 2028 2029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6 — No HF Dataset: build PyTorch Datasets directly from your data ===\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"Helsinki-NLP/opus-mt-zh-en\"   # tokenizer only; model will be from-scratch next\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class MarianPairDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_src=MAX_SRC, max_tgt=MAX_TGT):\n",
    "        self.cn = df[\"cn\"].tolist()\n",
    "        self.en = df[\"en\"].tolist()\n",
    "        self.tok = tokenizer\n",
    "        self.max_src = max_src\n",
    "        self.max_tgt = max_tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cn)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.cn[idx]; tgt = self.en[idx]\n",
    "        # Same-call style\n",
    "        pack = tokenizer(\n",
    "            src,\n",
    "            text_target=tgt,\n",
    "            max_length=MAX_SRC,\n",
    "            truncation=True\n",
    "        )\n",
    "        # If you need different lengths, do two calls as in the comment above\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(pack[\"input_ids\"]),\n",
    "            \"attention_mask\": torch.tensor(pack[\"attention_mask\"]),\n",
    "            \"labels\": torch.tensor(pack[\"labels\"]),\n",
    "        }\n",
    "\n",
    "train_ds = MarianPairDataset(train_df, tokenizer)\n",
    "valid_ds = MarianPairDataset(valid_df, tokenizer)\n",
    "test_ds  = MarianPairDataset(test_df,  tokenizer)\n",
    "\n",
    "print(\"PyTorch datasets:\", len(train_ds), len(valid_ds), len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494639c",
   "metadata": {},
   "source": [
    "##### Version 2 using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766805e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Cell 6 (fixed) — Build HF Datasets & tokenize for Marian (prep for training) ===\n",
    "# from transformers import AutoTokenizer\n",
    "# from datasets import Dataset, DatasetDict\n",
    "\n",
    "# MODEL_NAME = \"Helsinki-NLP/opus-mt-zh-en\"   # tokenizer only; model will be from-scratch next\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# # Preprocess: CN → input_ids, EN → labels (both truncated to MAX_SRC/MAX_TGT)\n",
    "# def preprocess(batch):\n",
    "#     # One call: inputs + labels via `text_target`\n",
    "#     model_inputs = tokenizer(\n",
    "#         batch[\"cn\"],\n",
    "#         text_target=batch[\"en\"],\n",
    "#         max_length=MAX_SRC,\n",
    "#         truncation=True\n",
    "#     )\n",
    "#     # If you want a different max length for targets, split into two calls:\n",
    "#     model_inputs = tokenizer(batch[\"cn\"], max_length=MAX_SRC, truncation=True)\n",
    "#     labels = tokenizer(text_target=batch[\"en\"], max_length=MAX_TGT, truncation=True)\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "\n",
    "# # Wrap pandas splits into HF DatasetDict\n",
    "# hf_ds = DatasetDict({\n",
    "#     \"train\": Dataset.from_pandas(train_df),\n",
    "#     \"validation\": Dataset.from_pandas(valid_df),\n",
    "#     \"test\": Dataset.from_pandas(test_df),\n",
    "# })\n",
    "\n",
    "# # Remove only columns that actually exist (some pandas versions don't add __index_level_0__)\n",
    "# cols_in = hf_ds[\"train\"].column_names\n",
    "# to_remove = [c for c in [\"cn\", \"en\", \"__index_level_0__\", \"index\"] if c in cols_in]\n",
    "\n",
    "# tok_ds = hf_ds.map(preprocess, batched=True, remove_columns=to_remove)\n",
    "# print(tok_ds)\n",
    "# print(\"Columns removed:\", to_remove)\n",
    "# print(\"Example tokenized keys:\", tok_ds[\"train\"][0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d49aa",
   "metadata": {},
   "source": [
    "### Create Marian Transformer *from scratch* + collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8866d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marian (from scratch) initialized. Parameters: 77.9M | Vocab size: 65001 | Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7 — Create Marian Transformer *from scratch* + collator ===\n",
    "from transformers import AutoConfig, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "import math\n",
    "\n",
    "MODEL_NAME = \"Helsinki-NLP/opus-mt-zh-en\"  # use Marian architecture config only\n",
    "\n",
    "# Load architecture hyperparameters (no weights), then build random-initialized model\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "model  = AutoModelForSeq2SeqLM.from_config(config)\n",
    "\n",
    "# Make sure embedding sizes match the tokenizer (safe even if already equal)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Move to GPU/CPU\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Collator handles dynamic padding for batches\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "\n",
    "# Quick model info\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Marian (from scratch) initialized. Parameters: {num_params/1e6:.1f}M | Vocab size: {len(tokenizer)} | Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f4151",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b198bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 8 — Metrics: BLEU only ===\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    ref_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(pred_texts, [ref_texts]).score\n",
    "    return {\"bleu\": bleu}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c961c67",
   "metadata": {},
   "source": [
    "### Trainer Setup + Train + Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e856e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9 — Unified Trainer (works with HF tok_ds OR PyTorch train_ds/valid_ds) ===\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import math, inspect, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- pick the datasets you actually created ----\n",
    "if 'tok_ds' in globals():                               # HF DatasetDict path (Cell 6)\n",
    "    train_dataset = tok_ds[\"train\"]\n",
    "    eval_dataset  = tok_ds[\"validation\"]\n",
    "elif 'train_ds' in globals() and 'valid_ds' in globals(): # Option B PyTorch path\n",
    "    train_dataset = train_ds\n",
    "    eval_dataset  = valid_ds\n",
    "else:\n",
    "    raise RuntimeError(\"No datasets found. Run Cell 6 (HF) or Cell 6 Option B (PyTorch) first.\")\n",
    "\n",
    "train_len = len(train_dataset)\n",
    "\n",
    "ckpt_dir = RUN_DIR / \"checkpoints\"\n",
    "best_dir = RUN_DIR / \"best_model\"\n",
    "\n",
    "# ---- HARD RESET to avoid incompatible old checkpoints (set False to resume later) ----\n",
    "CLEAN_START = False\n",
    "if CLEAN_START:\n",
    "    shutil.rmtree(ckpt_dir, ignore_errors=True)\n",
    "    shutil.rmtree(best_dir, ignore_errors=True)\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- step estimates for legacy fallbacks ----\n",
    "steps_per_epoch = max(1, math.ceil(train_len / max(1, BSZ)) // max(1, GRAD_ACCUM))\n",
    "total_steps     = steps_per_epoch * EPOCHS\n",
    "warmup_steps    = int(WARMUP_RATIO * total_steps)\n",
    "\n",
    "# ---- build TrainingArguments compatibly with your transformers version ----\n",
    "sig = set(inspect.signature(Seq2SeqTrainingArguments.__init__).parameters.keys())\n",
    "kw = dict(\n",
    "    output_dir=str(ckpt_dir),\n",
    "    overwrite_output_dir=True,          # ensure clean start\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BSZ,\n",
    "    per_device_eval_batch_size=BSZ,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    fp16=(DEVICE == \"cuda\"),\n",
    "    logging_steps=LOG_STEPS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# warmup\n",
    "if \"warmup_ratio\" in sig: kw[\"warmup_ratio\"] = WARMUP_RATIO\n",
    "elif \"warmup_steps\" in sig: kw[\"warmup_steps\"] = warmup_steps\n",
    "\n",
    "# label smoothing\n",
    "if \"label_smoothing_factor\" in sig: kw[\"label_smoothing_factor\"] = LABEL_SMOOTH\n",
    "\n",
    "# epoch-based strategies when available; otherwise step fallbacks\n",
    "has_eval_strategy = (\"evaluation_strategy\" in sig) or (\"eval_strategy\" in sig)\n",
    "has_save_strategy = (\"save_strategy\" in sig)\n",
    "\n",
    "if has_eval_strategy:\n",
    "    if \"evaluation_strategy\" in sig: kw[\"evaluation_strategy\"] = \"epoch\"\n",
    "    else: kw[\"eval_strategy\"] = \"epoch\"\n",
    "if has_save_strategy:\n",
    "    kw[\"save_strategy\"] = \"epoch\"\n",
    "if \"save_total_limit\" in sig: kw[\"save_total_limit\"] = 3\n",
    "if \"predict_with_generate\" in sig: kw[\"predict_with_generate\"] = True\n",
    "if \"report_to\" in sig: kw[\"report_to\"] = \"none\"\n",
    "\n",
    "if not has_eval_strategy and \"eval_steps\" in sig: kw[\"eval_steps\"] = steps_per_epoch\n",
    "if not has_save_strategy and \"save_steps\" in sig: kw[\"save_steps\"] = steps_per_epoch\n",
    "\n",
    "# enable \"load_best_model_at_end\" only if both strategies exist (prevents mismatch error)\n",
    "if ((\"load_best_model_at_end\" in sig) and (\"metric_for_best_model\" in sig)\n",
    "    and (\"greater_is_better\" in sig) and has_eval_strategy and has_save_strategy):\n",
    "    kw[\"load_best_model_at_end\"] = True\n",
    "    kw[\"metric_for_best_model\"] = \"bleu\"\n",
    "    kw[\"greater_is_better\"] = True\n",
    "\n",
    "args = Seq2SeqTrainingArguments(**kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17072\\496849062.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\data\\data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1016' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1015/1015 01:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Trainer ----\n",
    "try:\n",
    "    from transformers import EarlyStoppingCallback\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "except Exception:\n",
    "    callbacks = []\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,                      # from-scratch Marian (Cell 7)\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,  # BLEU-only (Cell 8)\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# ---- Train (NO RESUME this run) ----\n",
    "trainer.train(resume_from_checkpoint=None)\n",
    "\n",
    "# ---- Save model/tokenizer ----\n",
    "trainer.save_model(best_dir)\n",
    "tokenizer.save_pretrained(best_dir)\n",
    "\n",
    "best_ckpt  = getattr(trainer.state, \"best_model_checkpoint\", None)\n",
    "best_metric= getattr(trainer.state, \"best_metric\", None)\n",
    "print(\"Best checkpoint:\", best_ckpt)\n",
    "print(\"Best BLEU:\", best_metric)\n",
    "print(\"Saved to:\", best_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 12A — Classification-style metrics (token-level) + BLEU ===\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sacrebleu\n",
    "\n",
    "def compute_metrics_cls(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):  # some Trainer versions return (logits, ...)\n",
    "        preds = preds[0]\n",
    "\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "\n",
    "    # ----- token-level classification view -----\n",
    "    # Flatten and ignore PAD in labels\n",
    "    y_true = np.where(labels != -100, labels, pad_id).reshape(-1)\n",
    "    y_pred = preds.reshape(-1)\n",
    "    keep = (y_true != pad_id)\n",
    "    y_true_m = y_true[keep]\n",
    "    y_pred_m = y_pred[keep]\n",
    "\n",
    "    out = {}\n",
    "    if y_true_m.size > 0:\n",
    "        out[\"tok_acc\"]            = accuracy_score(y_true_m, y_pred_m)\n",
    "        out[\"tok_f1_micro\"]       = f1_score(y_true_m, y_pred_m, average=\"micro\", zero_division=0)\n",
    "        out[\"tok_f1_macro\"]       = f1_score(y_true_m, y_pred_m, average=\"macro\", zero_division=0)\n",
    "        out[\"tok_precision_macro\"]= precision_score(y_true_m, y_pred_m, average=\"macro\", zero_division=0)\n",
    "        out[\"tok_recall_macro\"]   = recall_score(y_true_m, y_pred_m, average=\"macro\", zero_division=0)\n",
    "\n",
    "    # ----- BLEU (text-level) -----\n",
    "    pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels_for_decode = np.where(labels != -100, labels, pad_id)\n",
    "    ref_texts  = tokenizer.batch_decode(labels_for_decode, skip_special_tokens=True)\n",
    "    out[\"bleu\"] = sacrebleu.corpus_bleu(pred_texts, [ref_texts]).score\n",
    "    return out\n",
    "\n",
    "\n",
    "# For the current run (no retrain), attach and evaluate VALID once:\n",
    "trainer.compute_metrics = compute_metrics_cls\n",
    "valid_results = trainer.evaluate(eval_dataset=eval_dataset)  # uses the same eval_dataset as Cell 9\n",
    "import pandas as pd; display(pd.DataFrame([valid_results]).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 12C — Overall classification metrics on TEST ===\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate_texts(texts, batch_size=16, num_beams=4, max_new_tokens=128,\n",
    "                    no_repeat_ngram_size=3, length_penalty=1.0):\n",
    "    mdl = trainer.model.to(DEVICE).eval() if 'trainer' in globals() else model.to(DEVICE).eval()\n",
    "    outs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating TEST\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True,\n",
    "                        max_length=MAX_SRC).to(DEVICE)\n",
    "        gen = mdl.generate(\n",
    "            **enc,\n",
    "            num_beams=num_beams,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            length_penalty=length_penalty,\n",
    "        )\n",
    "        outs.extend(tokenizer.batch_decode(gen, skip_special_tokens=True))\n",
    "    return outs\n",
    "\n",
    "# 1) Translate TEST\n",
    "test_src = test_df[\"cn\"].tolist()\n",
    "test_ref = test_df[\"en\"].tolist()\n",
    "test_pred = translate_texts(test_src, batch_size=16)\n",
    "\n",
    "# 2) Token-level multiclass metrics (re-encode refs & preds) — FIXED equal-length pad\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "MAX_TGT_EVAL = int(globals().get(\"MAX_TGT\", 128))  # fallback if MAX_TGT not defined\n",
    "pad_id = tokenizer.pad_token_id\n",
    "\n",
    "# Use identical width for both sides to avoid shape mismatch\n",
    "enc_ref  = tokenizer(\n",
    "    test_ref, padding='max_length', truncation=True, max_length=MAX_TGT_EVAL, return_tensors=\"np\"\n",
    ")\n",
    "enc_pred = tokenizer(\n",
    "    test_pred, padding='max_length', truncation=True, max_length=MAX_TGT_EVAL, return_tensors=\"np\"\n",
    ")\n",
    "\n",
    "# Defensive: enforce same width (in case you change one side later)\n",
    "L = min(enc_ref[\"input_ids\"].shape[1], enc_pred[\"input_ids\"].shape[1])\n",
    "y_true = enc_ref[\"input_ids\"][:, :L].reshape(-1)\n",
    "y_pred = enc_pred[\"input_ids\"][:, :L].reshape(-1)\n",
    "\n",
    "# Ignore PAD positions in the reference\n",
    "keep = (y_true != pad_id)\n",
    "y_true_m = y_true[keep]\n",
    "y_pred_m = y_pred[keep]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sacrebleu, pandas as pd\n",
    "overall = {\n",
    "    \"bleu\": sacrebleu.corpus_bleu(test_pred, [test_ref]).score,\n",
    "    \"tok_acc\": accuracy_score(y_true_m, y_pred_m),\n",
    "    \"tok_f1_micro\": f1_score(y_true_m, y_pred_m, average=\"micro\", zero_division=0),\n",
    "    \"tok_f1_macro\": f1_score(y_true_m, y_pred_m, average=\"macro\", zero_division=0),\n",
    "    \"tok_precision_macro\": precision_score(y_true_m, y_pred_m, average=\"macro\", zero_division=0),\n",
    "    \"tok_recall_macro\": recall_score(y_true_m, y_pred_m, average=\"macro\", zero_division=0),\n",
    "}\n",
    "display(pd.DataFrame([overall]).round(4))\n",
    "\n",
    "# 3) Save artifacts\n",
    "EVAL_DIR = RUN_DIR / \"eval\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "pd.DataFrame({\"cn\": test_src, \"ref_en\": test_ref, \"pred_en\": test_pred}).to_csv(EVAL_DIR / \"test_preds.csv\", index=False)\n",
    "pd.DataFrame([overall]).to_csv(EVAL_DIR / \"test_classification_metrics.csv\", index=False)\n",
    "print(\"Saved:\", EVAL_DIR / \"test_preds.csv\")\n",
    "print(\"Saved:\", EVAL_DIR / \"test_classification_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9bb94",
   "metadata": {},
   "source": [
    "### Evaluate & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 10 — Evaluate on VALID & TEST + sample translations (BLEU/chrF) ===\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import json\n",
    "\n",
    "# 1) Load best saved model if present, else use the current model in memory\n",
    "best_dir = RUN_DIR / \"best_model\"\n",
    "eval_model = None\n",
    "try:\n",
    "    if best_dir.exists():\n",
    "        eval_model = AutoModelForSeq2SeqLM.from_pretrained(best_dir).to(DEVICE)\n",
    "        print(\"Loaded best model from:\", best_dir)\n",
    "except Exception as e:\n",
    "    print(\"Could not load best model from disk, using in-memory model. Reason:\", e)\n",
    "\n",
    "if eval_model is None:\n",
    "    eval_model = model  # fallback to the model you just trained\n",
    "\n",
    "# 2) Translate helper (batched) with beam search\n",
    "@torch.no_grad()\n",
    "def translate_marian(texts, beams=4, max_new_tokens=128, bs=64):\n",
    "    outs = []\n",
    "    eval_model.eval()\n",
    "    for i in range(0, len(texts), bs):\n",
    "        batch = texts[i:i+bs]\n",
    "        enc = tokenizer(batch, return_tensors=\"pt\", padding=True,\n",
    "                        truncation=True, max_length=MAX_SRC).to(DEVICE)\n",
    "        gen = eval_model.generate(\n",
    "            **enc,\n",
    "            num_beams=beams,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            no_repeat_ngram_size=3,\n",
    "            length_penalty=1.0,\n",
    "        )\n",
    "        outs += tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "    return outs\n",
    "\n",
    "# 3) Evaluate on VALID\n",
    "valid_pred = translate_marian(valid_df[\"cn\"].tolist(), beams=4, max_new_tokens=128, bs=48)\n",
    "valid_bleu = sacrebleu.corpus_bleu(valid_pred, [valid_df[\"en\"].tolist()]).score\n",
    "valid_chrf = sacrebleu.corpus_chrf(valid_pred, [valid_df[\"en\"].tolist()]).score\n",
    "\n",
    "# 4) Evaluate on TEST\n",
    "test_pred  = translate_marian(test_df[\"cn\"].tolist(),  beams=4, max_new_tokens=128, bs=48)\n",
    "test_bleu  = sacrebleu.corpus_bleu(test_pred,  [test_df[\"en\"].tolist()]).score\n",
    "test_chrf  = sacrebleu.corpus_chrf(test_pred,  [test_df[\"en\"].tolist()]).score\n",
    "\n",
    "print(f\"VALID  | BLEU {valid_bleu:.2f}  chrF {valid_chrf:.2f}\")\n",
    "print(f\"TEST   | BLEU {test_bleu:.2f}  chrF {test_chrf:.2f}\")\n",
    "\n",
    "# 5) Show a small sample table for the report\n",
    "display(pd.DataFrame({\n",
    "    \"CN\": valid_df[\"cn\"].head(10).tolist(),\n",
    "    \"REF_EN\": valid_df[\"en\"].head(10).tolist(),\n",
    "    \"PRED_EN\": valid_pred[:10]\n",
    "}))\n",
    "\n",
    "# 6) Save metrics and sample predictions\n",
    "metrics = {\n",
    "    \"valid_bleu\": float(valid_bleu),\n",
    "    \"valid_chrf\": float(valid_chrf),\n",
    "    \"test_bleu\": float(test_bleu),\n",
    "    \"test_chrf\": float(test_chrf),\n",
    "}\n",
    "(RUN_DIR / \"eval\").mkdir(parents=True, exist_ok=True)\n",
    "(RUN_DIR / \"eval\" / \"metrics.json\").write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "pd.DataFrame({\n",
    "    \"cn\": valid_df[\"cn\"],\n",
    "    \"ref_en\": valid_df[\"en\"],\n",
    "    \"pred_en\": valid_pred\n",
    "}).to_csv(RUN_DIR / \"eval\" / \"valid_preds.csv\", index=False)\n",
    "pd.DataFrame({\n",
    "    \"cn\": test_df[\"cn\"],\n",
    "    \"ref_en\": test_df[\"en\"],\n",
    "    \"pred_en\": test_pred\n",
    "}).to_csv(RUN_DIR / \"eval\" / \"test_preds.csv\", index=False)\n",
    "print(\"Saved metrics & preds to:\", RUN_DIR / \"eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb16310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 11 — Plot training curves (BLEU/chrF over epochs) & save artifacts (no LR) ===\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = getattr(trainer.state, \"log_history\", None)\n",
    "if not logs:\n",
    "    print(\"No log history found on this Trainer instance.\")\n",
    "else:\n",
    "    df_logs = pd.DataFrame(logs)\n",
    "\n",
    "    # Keep rows that contain any eval metric we care about\n",
    "    wanted = [\"eval_bleu\", \"eval_chrf\", \"eval_loss\"]\n",
    "    mask = False\n",
    "    for c in wanted:\n",
    "        if c in df_logs.columns:\n",
    "            mask = mask | df_logs[c].notna()\n",
    "    if mask is False:\n",
    "        print(\"No evaluation metrics recorded.\")\n",
    "        display(df_logs.tail(15))\n",
    "    else:\n",
    "        cols = [\"epoch\"] + [c for c in wanted if c in df_logs.columns]\n",
    "        eval_df = df_logs.loc[mask, cols].reset_index(drop=True)\n",
    "\n",
    "        # Drop any columns that are all-NaN (e.g., if chrF isn’t logged)\n",
    "        eval_df = eval_df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "        if len(eval_df) == 0 or \"epoch\" not in eval_df.columns:\n",
    "            print(\"No evaluation metrics recorded.\")\n",
    "            display(df_logs.tail(15))\n",
    "        else:\n",
    "            display(eval_df)\n",
    "\n",
    "            # Plot BLEU/chrF if present; otherwise plot eval_loss\n",
    "            plt.figure()\n",
    "            plotted = False\n",
    "            if \"eval_bleu\" in eval_df.columns:\n",
    "                plt.plot(eval_df[\"epoch\"], eval_df[\"eval_bleu\"], marker=\"o\", label=\"BLEU (valid)\")\n",
    "                plotted = True\n",
    "            if \"eval_chrf\" in eval_df.columns:\n",
    "                plt.plot(eval_df[\"epoch\"], eval_df[\"eval_chrf\"], marker=\"o\", label=\"chrF (valid)\")\n",
    "                plotted = True\n",
    "            if not plotted and \"eval_loss\" in eval_df.columns:\n",
    "                plt.plot(eval_df[\"epoch\"], eval_df[\"eval_loss\"], marker=\"o\", label=\"Loss (valid)\")\n",
    "\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Score\")\n",
    "            plt.title(\"Validation metrics over training\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "            (RUN_DIR / \"eval\").mkdir(parents=True, exist_ok=True)\n",
    "            fig_path = RUN_DIR / \"eval\" / \"training_curves.png\"\n",
    "            plt.savefig(fig_path, bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            print(\"Saved plot to:\", fig_path)\n",
    "\n",
    "            # Save metrics table\n",
    "            csv_path = RUN_DIR / \"eval\" / \"training_metrics.csv\"\n",
    "            eval_df.to_csv(csv_path, index=False)\n",
    "            print(\"Saved metrics CSV to:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === UI Cell — Easy translator (Gradio) ===\n",
    "# # If you don't have Gradio yet, uncomment the next line:\n",
    "# !pip install -q gradio\n",
    "\n",
    "# import time, torch\n",
    "# import gradio as gr\n",
    "# from pathlib import Path\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# # ---- Paths & device ----\n",
    "# BEST_DIR = RUN_DIR / \"best_model\" if 'RUN_DIR' in globals() else Path(\"marian_zh_en_scratch_run/best_model\")\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # ---- Load tokenizer (prefer your saved one; else Marian base) ----\n",
    "# TOK_NAME = str(BEST_DIR) if BEST_DIR.exists() else \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(TOK_NAME)\n",
    "\n",
    "# # ---- Get / load model once ----\n",
    "# _loaded_model = None\n",
    "# def get_model():\n",
    "#     global _loaded_model\n",
    "#     if _loaded_model is not None:\n",
    "#         return _loaded_model\n",
    "#     # 1) Prefer your saved best model\n",
    "#     if BEST_DIR.exists():\n",
    "#         try:\n",
    "#             _loaded_model = AutoModelForSeq2SeqLM.from_pretrained(BEST_DIR).to(DEVICE).eval()\n",
    "#             return _loaded_model\n",
    "#         except Exception as e:\n",
    "#             print(\"Warning: could not load best_model from disk:\", e)\n",
    "#     # 2) If you trained a model in this session, reuse it\n",
    "#     if 'model' in globals():\n",
    "#         _loaded_model = model.to(DEVICE).eval()\n",
    "#         return _loaded_model\n",
    "#     # 3) Fallback to base Marian (not fine-tuned)\n",
    "#     _loaded_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\").to(DEVICE).eval()\n",
    "#     return _loaded_model\n",
    "\n",
    "# # ---- Translator function for Gradio ----\n",
    "# @torch.no_grad()\n",
    "# def translate_ui(text, beams, max_new_tokens, no_repeat_ngram, length_penalty):\n",
    "#     text = (text or \"\").strip()\n",
    "#     if not text:\n",
    "#         return \"\", \"Please enter Chinese text.\"\n",
    "\n",
    "#     mdl = get_model()\n",
    "#     t0 = time.time()\n",
    "\n",
    "#     enc = tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True,\n",
    "#                     max_length=globals().get(\"MAX_SRC\", 128)).to(DEVICE)\n",
    "\n",
    "#     gen = mdl.generate(\n",
    "#         **enc,\n",
    "#         num_beams=int(beams),\n",
    "#         max_new_tokens=int(max_new_tokens),\n",
    "#         no_repeat_ngram_size=int(no_repeat_ngram),\n",
    "#         length_penalty=float(length_penalty),\n",
    "#     )\n",
    "#     out = tokenizer.batch_decode(gen, skip_special_tokens=True)[0]\n",
    "#     dt = time.time() - t0\n",
    "#     info = f\"Device: {DEVICE} • Beam: {beams} • Max tokens: {max_new_tokens} • Time: {dt*1000:.0f} ms\"\n",
    "#     return out, info\n",
    "\n",
    "# # ---- Build UI ----\n",
    "# with gr.Blocks(title=\"CN → EN Translator\") as demo:\n",
    "#     gr.Markdown(\"## 🇨🇳 ➜ 🇬🇧 CN → EN Translator (Marian)\\n\"\n",
    "#                 \"- Uses your **best_model** if found\\n\"\n",
    "#                 \"- GPU auto-used if available\\n\"\n",
    "#                 \"- Tweak beam size & max tokens as needed\")\n",
    "\n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             inp = gr.Textbox(label=\"Chinese input\", lines=5, placeholder=\"输入中文句子…\")\n",
    "#             beams = gr.Slider(1, 8, value=4, step=1, label=\"Beam size\")\n",
    "#             max_new = gr.Slider(16, 256, value=128, step=8, label=\"Max new tokens\")\n",
    "#             no_rep = gr.Slider(0, 5, value=3, step=1, label=\"No-repeat n-gram size\")\n",
    "#             lp = gr.Slider(-1.0, 2.0, value=1.0, step=0.1, label=\"Length penalty\")\n",
    "#             btn = gr.Button(\"Translate 🚀\")\n",
    "#         with gr.Column():\n",
    "#             out = gr.Textbox(label=\"English translation\", lines=5)\n",
    "#             meta = gr.Markdown()\n",
    "\n",
    "#     btn.click(fn=translate_ui, inputs=[inp, beams, max_new, no_rep, lp], outputs=[out, meta])\n",
    "\n",
    "# demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
